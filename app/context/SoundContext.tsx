"use client";

import React, { createContext, useContext, useState, useEffect, useRef, useCallback } from "react";

type SoundType = "click" | "ticking" | "success" | "shutter" | "hover";

interface SoundContextType {
  isMuted: boolean;
  toggleMute: () => void;
  playSound: (type: SoundType) => void;
  stopSound: (type: SoundType) => void;
}

const SoundContext = createContext<SoundContextType | undefined>(undefined);

export const SoundProvider = ({ children }: { children: React.ReactNode }) => {
  const [isMuted, setIsMuted] = useState(false);
  const [isReady, setIsReady] = useState(false);

  // Web Audio API Context
  const audioCtxRef = useRef<AudioContext | null>(null);
  // Bufor (PamiÄ™Ä‡ RAM) na dÅºwiÄ™ki - dziÄ™ki temu odpalajÄ… siÄ™ w 0ms
  const buffersRef = useRef<Record<string, AudioBuffer>>({});
  // Referencje do aktualnie grajÄ…cych ÅºrÃ³deÅ‚ (Å¼eby mÃ³c je zatrzymaÄ‡, np. tykanie)
  const activeSourcesRef = useRef<Record<string, AudioBufferSourceNode>>({});

  // 1. INICJALIZACJA I ÅADOWANIE PLIKÃ“W DO PAMIÄ˜CI
  useEffect(() => {
    // Tworzymy kontekst Audio tylko raz
    const CtxClass = (window.AudioContext || (window as any).webkitAudioContext);
    const ctx = new CtxClass();
    audioCtxRef.current = ctx;

    // Lista plikÃ³w do zaÅ‚adowania
    const soundsToLoad: Record<string, string> = {
      "timer": "/sounds/ui/timer.mp3",
      "hover": "/sounds/ui/hover.mp3",
      "click-1": "/sounds/ui/click1.mp3",
      "click-2": "/sounds/ui/click2.mp3",
      "click-3": "/sounds/ui/click3.mp3",
      "click-4": "/sounds/ui/click4.mp3",
    };

    // Funkcja pobierajÄ…ca i dekodujÄ…ca plik
    const loadSound = async (key: string, url: string) => {
      try {
        const response = await fetch(url);
        
        // 1. SprawdÅº czy plik w ogÃ³le istnieje (Status 200 OK)
        if (!response.ok) {
          throw new Error(`BÅ‚Ä…d sieci: ${response.status} ${response.statusText}`);
        }

        // 2. SprawdÅº czy to na pewno audio (opcjonalne, ale pomocne)
        const contentType = response.headers.get("content-type");
        if (contentType && contentType.includes("text/html")) {
           throw new Error(`Pobrano stronÄ™ HTML zamiast pliku audio! SprawdÅº Å›cieÅ¼kÄ™ do pliku.`);
        }

        const arrayBuffer = await response.arrayBuffer();
        
        // 3. Dekodowanie
        const decodedBuffer = await ctx.decodeAudioData(arrayBuffer);
        buffersRef.current[key] = decodedBuffer;
        
      } catch (err) {
        // Tu zobaczysz w konsoli dokÅ‚adnie, ktÃ³ry plik robi problem
        console.error(`âŒ BÅÄ„D Å‚adowania dÅºwiÄ™ku: "${key}" (URL: ${url})`, err);
      }
    };

    // Åadujemy wszystko rÃ³wnolegle
    Promise.all(
      Object.entries(soundsToLoad).map(([key, url]) => loadSound(key, url))
    ).then(() => {
      setIsReady(true);
      console.log("Audio System Ready ğŸ”Š");
    });

    return () => {
      ctx.close();
    };
  }, []);

  // 2. FUNKCJA ODTWARZANIA (Niskopoziomowa)
  const playSound = useCallback((type: SoundType) => {
    if (isMuted || !audioCtxRef.current || !isReady) return;

    const ctx = audioCtxRef.current;

    // PrzeglÄ…darki usypiajÄ… AudioContext do pierwszej interakcji. Budzimy go.
    if (ctx.state === "suspended") {
      ctx.resume();
    }

   let bufferKey: string = type;
    let volume = 1.0;
    let playbackRate = 1.0;
    let loop = false;

    // LOGIKA LOSOWANIA I GÅOÅšNOÅšCI
    if (type === "click") {
      // Losujemy wariant
      const variant = Math.floor(Math.random() * 4) + 1;
      bufferKey = `click-${variant}`;
      
      // Losowy pitch (wysokoÅ›Ä‡ dÅºwiÄ™ku) dla realizmu
      playbackRate = 0.95 + Math.random() * 0.1;

      // Specjalna gÅ‚oÅ›noÅ›Ä‡ dla click3 (jak ustalaÅ‚eÅ› wczeÅ›niej)
      volume = variant === 3 ? 1.0 : 0.5;
    
    } else if (type === "ticking") {
      volume = 0.4; // GÅ‚oÅ›noÅ›Ä‡ tykania ustawiamy tutaj bazowo, ale Timer jÄ… nadpisuje swoim volume
      loop = true;  // ZapÄ™tlamy
    } else {
      volume = 0.5;
    }

    // Pobieramy zdekodowany dÅºwiÄ™k z pamiÄ™ci
    const buffer = buffersRef.current[bufferKey];
    if (!buffer) return;

    // Tworzymy ÅºrÃ³dÅ‚o dÅºwiÄ™ku
    const source = ctx.createBufferSource();
    source.buffer = buffer;
    source.loop = loop;
    source.playbackRate.value = playbackRate;

    // Tworzymy wÄ™zeÅ‚ gÅ‚oÅ›noÅ›ci (GainNode)
    const gainNode = ctx.createGain();
    gainNode.gain.value = volume;

    // ÅÄ…czymy: Å¹rÃ³dÅ‚o -> GÅ‚oÅ›noÅ›Ä‡ -> GÅ‚oÅ›niki
    source.connect(gainNode);
    gainNode.connect(ctx.destination);

    // Start!
    source.start(0);

    // Zapisujemy referencjÄ™ (tylko dla dÅ‚ugich dÅºwiÄ™kÃ³w, Å¼eby mÃ³c je zatrzymaÄ‡)
    if (type === "ticking") {
      // JeÅ›li coÅ› juÅ¼ tykaÅ‚o, zatrzymaj to najpierw
      if (activeSourcesRef.current["ticking"]) {
        try { activeSourcesRef.current["ticking"].stop(); } catch(e){}
      }
      activeSourcesRef.current["ticking"] = source;
    }
  }, [isMuted, isReady]);

  // 3. FUNKCJA ZATRZYMYWANIA
  const stopSound = useCallback((type: SoundType) => {
    const source = activeSourcesRef.current[type];
    if (source) {
      try {
        source.stop();
      } catch (e) {
        // Ignorujemy bÅ‚Ä™dy, jeÅ›li dÅºwiÄ™k juÅ¼ siÄ™ skoÅ„czyÅ‚
      }
      delete activeSourcesRef.current[type];
    }
  }, []);

  const toggleMute = () => {
    // Przy odciszaniu musimy upewniÄ‡ siÄ™, Å¼e kontekst jest aktywny
    if (isMuted && audioCtxRef.current?.state === "suspended") {
      audioCtxRef.current.resume();
    }
    setIsMuted((prev) => !prev);
  };

  // 4. GLOBALNY LISTENER - ZMIANA NA POINTERDOWN (SZYBSZE NIÅ» CLICK)
  useEffect(() => {
    const handleGlobalInteraction = () => {
      // Budzimy kontekst przy pierwszym dotkniÄ™ciu
      if (audioCtxRef.current?.state === "suspended") {
        audioCtxRef.current.resume();
      }
      playSound("click");
    };

    // UÅ¼ywamy 'pointerdown' zamiast 'click'. 
    // 'click' czeka na puszczenie przycisku myszy. 'pointerdown' dziaÅ‚a natychmiast po wciÅ›niÄ™ciu.
    window.addEventListener("pointerdown", handleGlobalInteraction);
    
    return () => window.removeEventListener("pointerdown", handleGlobalInteraction);
  }, [playSound]);

  return (
    <SoundContext.Provider value={{ isMuted, toggleMute, playSound, stopSound }}>
      {children}
    </SoundContext.Provider>
  );
};

export const useSound = () => {
  const context = useContext(SoundContext);
  if (!context) throw new Error("useSound must be used within a SoundProvider");
  return context;
};